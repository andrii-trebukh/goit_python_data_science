{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import keras\n",
    "# from keras import ops\n",
    "# from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "from vehicle_license_plate_recognizer import recognizer\n",
    "from vehicle_license_plate_recognizer import recognizer_enhanced as reco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters =[ch for ch in \" -0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"]\n",
    "\n",
    "# model_chars_recognition = keras.models.load_model(\n",
    "#     \"smbls_recogn_based_on_captcha_method.keras\",\n",
    "#     compile=False\n",
    "# )\n",
    "\n",
    "# # characters = [' ', '-', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "\n",
    "# char_to_num = keras.layers.StringLookup(vocabulary=list(characters), mask_token=None)\n",
    "\n",
    "# num_to_char = keras.layers.StringLookup(\n",
    "#     vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    "# )\n",
    "\n",
    "# def ctc_decode(y_pred, input_length, greedy=True, beam_width=100, top_paths=1):\n",
    "#     input_shape = keras.ops.shape(y_pred)\n",
    "#     num_samples, num_steps = input_shape[0], input_shape[1]\n",
    "#     y_pred = keras.ops.log(keras.ops.transpose(y_pred, axes=[1, 0, 2]) + keras.backend.epsilon())\n",
    "#     input_length = keras.ops.cast(input_length, dtype=\"int32\")\n",
    "\n",
    "#     if greedy:\n",
    "#         (decoded, log_prob) = tf.nn.ctc_greedy_decoder(\n",
    "#             inputs=y_pred, sequence_length=input_length\n",
    "#         )\n",
    "#     else:\n",
    "#         (decoded, log_prob) = tf.compat.v1.nn.ctc_beam_search_decoder(\n",
    "#             inputs=y_pred,\n",
    "#             sequence_length=input_length,\n",
    "#             beam_width=beam_width,\n",
    "#             top_paths=top_paths,\n",
    "#         )\n",
    "#     decoded_dense = []\n",
    "#     for st in decoded:\n",
    "#         st = tf.SparseTensor(st.indices, st.values, (num_samples, num_steps))\n",
    "#         decoded_dense.append(tf.sparse.to_dense(sp_input=st, default_value=-1))\n",
    "#     return (decoded_dense, log_prob)\n",
    "\n",
    "\n",
    "# # A utility function to decode the output of the network\n",
    "# def decode_batch_predictions(pred):\n",
    "#     max_length = 8\n",
    "#     input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "#     # Use greedy search. For complex tasks, you can use beam search\n",
    "#     results = ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
    "#         :, :max_length\n",
    "#     ]\n",
    "#     # Iterate over the results and get back the text\n",
    "#     output_text = []\n",
    "#     for res in results:\n",
    "#         res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "#         output_text.append(res)\n",
    "#     return output_text\n",
    "\n",
    "\n",
    "# # def recognize_chars(img: Image) -> str:\n",
    "# #     img_width = 128\n",
    "# #     img_height = 32\n",
    "\n",
    "# #     # mk image preprocessing to model input\n",
    "# #     img = tf.convert_to_tensor(img)\n",
    "# #     img = tf.image.rgb_to_grayscale(img)\n",
    "# #     img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "# #     img = ops.image.resize(img, [img_height, img_width])\n",
    "# #     img = ops.transpose(img, axes=[1, 0, 2])\n",
    "# #     img = tf.data.Dataset.from_tensor_slices(([img, ], ))\n",
    "# #     img = img.batch(1).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# #     preds = model_chars_recognition.predict(img)\n",
    "# #     return decode_batch_predictions(preds)[0]\n",
    "\n",
    "# def recognize_chars(\n",
    "#         img: Image,\n",
    "#         model: keras.models = model_chars_recognition\n",
    "# ) -> str:\n",
    "    \n",
    "#     img_width = 128\n",
    "#     img_height = 32\n",
    "\n",
    "#     # make image preprocessing before model input\n",
    "#     img = tf.convert_to_tensor(img)\n",
    "#     img = tf.image.rgb_to_grayscale(img)\n",
    "#     img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "#     img = keras.ops.image.resize(img, [img_height, img_width])\n",
    "#     img = keras.ops.transpose(img, axes=[1, 0, 2])\n",
    "#     img = tf.reshape(img, [1, 128, 32, 1])\n",
    "\n",
    "#     # make prediction\n",
    "#     preds = model.predict(img)\n",
    "#     preds = decode_batch_predictions(preds)[0]\n",
    "    \n",
    "#     # if prediction contains [UNK] - recogintion failed, return None\n",
    "#     return None if preds.find(\"[UNK]\") != -1 else preds\n",
    "#     # if preds.find(\"[UNK]\"):\n",
    "#     #     return\n",
    "\n",
    "#     # return preds\n",
    "\n",
    "# img = Image.open(\"/home/sims/Projects/keras_cv_modules/test_dataset/plates_dataset_pure/000-01EE.png\")\n",
    "# recognize_chars(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urllib.request.urlretrieve( \n",
    "#   'https://cdn2.riastatic.com/photosnew/auto/photo/volkswagen_polo__567826982bx.jpg', \n",
    "#    \"img.jpg\") \n",
    "# img = Image.open(\"\")\n",
    "\n",
    "# _, _, txt = reco.recognize(img)\n",
    "\n",
    "# txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(image2, plate2, y_pred2, y_true):\n",
    "    title = \"Ok!\" if y_pred2 == y_true else \"Fail\"\n",
    "    title += f\"  y_true:{y_true}, y_pred:{y_pred2}\"\n",
    "    print(title)\n",
    "    _, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    # ax[0].imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "    # ax[0].axis(\"off\")\n",
    "\n",
    "    # if plate1 is not None:\n",
    "    #     ax[1].imshow(cv2.cvtColor(plate1, cv2.COLOR_BGR2RGB))\n",
    "    # else:\n",
    "    #     ax[1].set_title(\"None\")\n",
    "    # ax[1].axis(\"off\")\n",
    "\n",
    "    \n",
    "    ax[0].imshow(image2)\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    if plate2 is not None:\n",
    "        ax[1].imshow(plate2)\n",
    "    else:\n",
    "        ax[1].set_title(\"None\")\n",
    "    ax[1].axis(\"off\")\n",
    "    \n",
    "    # if chars is not None and len(chars) != 0:\n",
    "    #     plt.figure(figsize=(1,1))\n",
    "    #     plt.axis('off')\n",
    "    #     for index, char in zip(range(1, len(chars) + 1), chars):\n",
    "    #         plt.subplot(1, len(chars) + 1, index)\n",
    "    #         fig = plt.imshow(char, cmap='gray')\n",
    "    #         fig.axes.get_xaxis().set_visible(False)\n",
    "    #         fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_path = Path(\"test_dataset/auto_ria\")\n",
    "\n",
    "for file in test_ds_path.iterdir():\n",
    "    if file.suffix != \".jpg\":\n",
    "        continue\n",
    "    y_true = re.sub(r\"^\\d\\d\\d | |_\", \"\", file.stem)\n",
    "    \n",
    "    # Trying first model\n",
    "    # image = cv2.imread(file)\n",
    "\n",
    "    # try:\n",
    "    #     image_with_detect_plate, license_plate = recognizer.extract_plate(image)\n",
    "    # except:\n",
    "    #     image_with_detect_plate, license_plate = None, None\n",
    "\n",
    "    # if license_plate is not None:\n",
    "    #     characters_plate = recognizer.segment_characters(license_plate)\n",
    "    #     license_plate_predict = recognizer.predict_license_plate(\n",
    "    #         characters_plate,\n",
    "    #     )\n",
    "    # else:\n",
    "    #     characters_plate, license_plate_predict = None, None\n",
    "    \n",
    "    image2 = Image.open(file)\n",
    "    img_with_box2, plate2, y_pred2= reco.recognize(image2)\n",
    "    # y_pred2 = recognize_chars(plate2)\n",
    "\n",
    "    plot_results(\n",
    "        img_with_box2,\n",
    "        plate2,\n",
    "        y_pred2,\n",
    "        y_true\n",
    "    )\n",
    "\n",
    "    # break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
